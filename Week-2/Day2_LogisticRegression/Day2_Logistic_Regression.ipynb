{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3890d67a-bcb7-443c-928b-0b088dfb0621",
   "metadata": {},
   "source": [
    "# Day 2 - Logistic Regression (Andrew Ng ML Specialization)\n",
    "### Machine Learning Roadmap - Week 2 \n",
    "### Author - N Manish Kumar \n",
    "---\n",
    "\n",
    "Today I will be covering the foundations of Logistic Regression.\n",
    "\n",
    "This includes topics such as Modified model function, Sigmoid Function, Logistic Loss Function, Cost Function, Decision Boundary and Gradient Descent for Logistic Regression.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Logistic Regression Theory\n",
    "\n",
    "Logistic Regression is used for **binary classification**.  \n",
    "Instead of predicting a continuous value, we predict a probability between 0 and 1.\n",
    "\n",
    "---\n",
    "- \\( w \\) = weights  \n",
    "- \\( b \\) = bias  \n",
    "- \\( x \\) = input feature\n",
    "### 1.1. Logistic Regression Model Function\n",
    "$$\n",
    "z = w \\cdot x + b\n",
    "$$\n",
    "$$\n",
    "f_{w,b}(x)=\\sigma(z)\n",
    "$$\n",
    "This gives:\n",
    "- High probability → predicted class = 1  \n",
    "- Low probability → predicted class = 0  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2. Sigmoid Function\n",
    "We convert \\( z \\) into a probability using:\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "This ensures :\n",
    "$$\n",
    "0\\le \\sigma(z) \\le 1\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3. Prediction Rule\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\begin{cases}\n",
    "1 & \\text{if } f_{w,b}(x) \\ge 0.5 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4. Loss Function (Binary Cross-Entropy)\n",
    "\n",
    "Loss for a single training example :\n",
    "$$\n",
    "L(f,y) = - y \\log(f) - (1 - y) \\log(1-f)\n",
    "$$\n",
    "\n",
    "This strongly penalizes confident wrong predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Cost Function\n",
    "\n",
    "Average Loss over all \\(m\\) examples :\n",
    "$$ \n",
    "J(w,b) = \\frac{1}{m}\n",
    "\\sum_{i=1}^m\n",
    "\\left[\n",
    "-y^{(i)} \\log(f_{w,b}(x^{(i)})\n",
    "- (1 - y^{(i)}) \\log(1 - f_{w,b}(x^{(i)}))\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1.6. Gradient Descent Updates\n",
    "$$\n",
    "w := w - \\alpha \\cdot \\frac{1}{m}\n",
    "\\sum_{i=1}^m\n",
    "(f_{w,b}(x^{(i)}) - y^{(i)})\\cdot x^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b := b -\\alpha \\cdot \\frac{1}{m}\n",
    "\\sum_{i=1}^m\n",
    "(f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Load Binary Classification Dataset\n",
    "We will use Breast Cancer datset, which is a clean, binary (0/1), and perfect for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6381b839-bdc3-4253-8ce9-a57342f076c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load Dataset \n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df[\"target\"] = data.target  # target = 0 (malignant), 1 (benign)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1f80f-a3ca-417c-8872-7cdbbec43c5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8916e18-0b61-48fa-acaa-225a2893229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (455,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seperate Features and Target \n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Train/Test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd19f25-6ec8-4d5f-9e6d-712c54c243b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feature Scaling\n",
    "Logistic Regression requires feature scaling because:\n",
    "\n",
    "- Gradient descent converges faster\n",
    "\n",
    "- Model coefficients behave correctly\n",
    "\n",
    "- Sklearn’s solver performs better\n",
    "\n",
    "So we standardize all features to:\n",
    "$$\n",
    "x' = \\frac{x-\\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02fcc7e-0c33-4234-a8a2-2ecc4e6200f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Intialize Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Firt only on training data \n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply same transformation to test data \n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_train_s.shape , X_test_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8957ea9-84b5-4170-b6ef-550b40a79c08",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 5. Implementing Sigmoid and Model Function\n",
    "Logistic Model : $$ z = w \\cdot x + b $$\n",
    "\n",
    "$$f_{w,b}(x) = \\sigma (z)$$\n",
    "\n",
    "Sigmoid : $$ \\sigma(z) = \\frac{1}{(1 +e^{-z})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e03b08a-e2e2-4f6a-aad5-ba36170d0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid(0) = 0.5\n",
      "Output shape: (455,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Sigmoid Function ---\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# --- Model Function ---\n",
    "def logistic_model(X, w, b):\n",
    "    z = np.dot(X,w) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "# Testing the Functions\n",
    "# Test sigmoid\n",
    "print(\"Sigmoid(0) =\", sigmoid(0))  # Expect 0.5\n",
    "\n",
    "# Test logistic model with dummy values\n",
    "w_test = np.zeros(X_train_s.shape[1])\n",
    "b_test = 0\n",
    "\n",
    "print(\"Output shape:\", logistic_model(X_train_s, w_test, b_test).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314306e-80d8-4bd4-844e-c4d03c862cd6",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Implementing Cost Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dadaad-aa8c-442d-a694-97f77061c698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid(0) = 0.5\n",
      "Loss(y=1, f=0.5): 0.6931471803599453\n",
      "Loss(y=0, f=0.5): 0.6931471803599453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6931471803599452)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Function\n",
    "def compute_loss(f, y):\n",
    "    return -(y * np.log(f+ 1e-10) + (1 - y) * np.log(1 - f + 1e-10))\n",
    "\n",
    "# Cost Fucntion\n",
    "def compute_cost(X, y, w, b):\n",
    "    m = X.shape[0]\n",
    "    f_wb = logistic_model(X, w, b)\n",
    "\n",
    "    # Apply compute_loss elementwise\n",
    "    losses = compute_loss(f_wb, y)\n",
    "\n",
    "    cost = np.mean(losses)\n",
    "    return cost\n",
    "\n",
    "# Test sigmoid output (should be 0.5)\n",
    "print(\"Sigmoid(0) =\", sigmoid(0))\n",
    "\n",
    "# Test loss on a single example\n",
    "print(\"Loss(y=1, f=0.5):\", compute_loss(0.5, 1))  # around 0.693\n",
    "print(\"Loss(y=0, f=0.5):\", compute_loss(0.5, 0))  # around 0.693\n",
    "\n",
    "# Test cost with w=0, b=0\n",
    "w_test = np.zeros(X_train_s.shape[1])\n",
    "b_test = 0\n",
    "\n",
    "cost_test = compute_cost(X_train_s, y_train, w_test, b_test)\n",
    "cost_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3465100-2608-47aa-8ad2-d71b0a21756a",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Computing Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234ac24d-765f-4c13-bb5c-1527492ecc91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.34696345, 0.2011088 , 0.35362455, 0.33589733, 0.18126103]),\n",
       " np.float64(-0.12857142857142856))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Compute Predictions \n",
    "    f_wb = logistic_model(X, w, b)     # shape(m,)\n",
    "\n",
    "    # Compute error \n",
    "    error = f_wb - y           # shape (m,)\\\n",
    "\n",
    "    # Vectorized Gradients\n",
    "    dj_dw = (1/m) * np.dot(X.T, error)       # (n,)\n",
    "    dj_db = (1/m) * np.sum(error)            # scalar\n",
    "\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Testing Gradient Descent Function\n",
    "w_test = np.zeros(X_train_s.shape[1])\n",
    "b_test = 0\n",
    "\n",
    "dj_dw_test, dj_db_test = compute_gradient(X_train_s, y_train, w_test, b_test)\n",
    "\n",
    "dj_dw_test[:5], dj_db_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffc581-15a0-4a50-ad1f-4e80912fee30",
   "metadata": {},
   "source": [
    "--- \n",
    "## 8. Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddc7d8d-76e4-4426-a124-8b500f3da626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, b, alpha, num_iters):\n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Compute gradients\n",
    "        dj_dw, dj_db = compute_gradient(X, y, w, b)\n",
    "\n",
    "        # Update Parameters\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        # Save Cost every 10 iterations \n",
    "        if i % 10 == 0:\n",
    "            cost = compute_cost(X, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "    return w, b, J_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841a9db-159d-493c-a245-72471729c673",
   "metadata": {},
   "source": [
    "---\n",
    "### 8.1. Train Logistic Regression using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56afd804-7c01-48cf-a329-0b47a1c1ec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.53175099, -0.62892677, -0.500301  , -0.59325959, -0.17359117,\n",
       "         0.40497564, -0.79809361, -0.96654814,  0.14638751,  0.28414942,\n",
       "        -1.20328298,  0.12752864, -0.75462914, -0.89024864, -0.26762067,\n",
       "         0.83222063,  0.0276945 , -0.23455249,  0.43594883,  0.6817801 ,\n",
       "        -0.94336293, -1.27618725, -0.75998916, -0.92253936, -0.79057534,\n",
       "        -0.04601264, -0.95122349, -0.89674292, -1.15488048, -0.15782677]),\n",
       " np.float64(0.5220011296893541))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Parameters \n",
    "n = X_train_s.shape[1]   # number of features\n",
    "w_initial = np.zeros(n)\n",
    "b_initial = 0\n",
    "\n",
    "# HyperParameters\n",
    "alpha = 0.1\n",
    "num_iters = 2000\n",
    "\n",
    "# Train model\n",
    "w_gd, b_gd, J_history = gradient_descent(\n",
    "    X_train_s, y_train, w_initial, b_initial, alpha, num_iters\n",
    ")\n",
    "\n",
    "w_gd, b_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b37d1f-df77-4fa6-aa6b-d01d605f6e3c",
   "metadata": {},
   "source": [
    "--- \n",
    "### 8.2. Plot Cost Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e508d22-2dc3-4d59-81b1-12e5f1e246c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(J_history)\n",
    "plt.xlabel(\"Iteration (x10)\")\n",
    "plt.ylabel(\"Cost J(w,b)\")\n",
    "plt.title(\"Gradient Descent Cost Convergence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0673b-1f5f-4efb-b45c-b93e7c2df2f5",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5efd69-bc4b-4f48-b3cc-c6b626d5166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent Model Accuracy: 0.9912280701754386\n",
      "[[42  1]\n",
      " [ 0 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.99      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.99       114\n",
      "   macro avg       0.99      0.99      0.99       114\n",
      "weighted avg       0.99      0.99      0.99       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on test set using GD parameters\n",
    "probs_gd = logistic_model(X_test_s, w_gd, b_gd)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_gd = (probs_gd >= 0.5).astype(int)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_gd = accuracy_score(y_test, y_pred_gd)\n",
    "print(\"Gradient Descent Model Accuracy:\", accuracy_gd)\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_gd)\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_gd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e220d3-162b-4f25-b362-3d712e5f6a5a",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comparing with Sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647c4377-4c2e-414e-9c70-ac0548299cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred_sk = clf.predict(X_test_s)\n",
    "\n",
    "print(\"Sklearn Accuracy:\", accuracy_score(y_test, y_pred_sk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177eeae-672f-495c-b8c1-b1783b5434b2",
   "metadata": {},
   "source": [
    "---\n",
    "# 11. Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75aded2-aeed-45cf-bb0a-2b0a182a9d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_gd_params.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save sklearn model\n",
    "joblib.dump(clf, \"logistic_regression_sklearn.pkl\")\n",
    "\n",
    "# Save StandardScaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Save Gradient Descent Parameters\n",
    "gd_params = {\"w\": w_gd, \"b\": b_gd}\n",
    "joblib.dump(gd_params, \"logistic_regression_gd_params.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f895033-924e-4c49-afad-af3f6d2c3011",
   "metadata": {},
   "source": [
    "---\n",
    "# 📝 Day 2 Summary — Logistic Regression (From Scratch + Sklearn)\n",
    "\n",
    "Today I implemented Logistic Regression following Andrew Ng’s notation.  \n",
    "Key concepts covered:\n",
    "\n",
    "### 🔹 Theory\n",
    "- Sigmoid function:  \n",
    "  $$\n",
    "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "  $$\n",
    "- Model:  \n",
    "  $$\n",
    "  f_{w,b}(x) = \\sigma(w \\cdot x + b)\n",
    "  $$\n",
    "- Logistic loss for a single example:  \n",
    "  $$\n",
    "  L(f, y) = -y \\log(f) - (1-y)\\log(1-f)\n",
    "  $$\n",
    "- Cost function (average loss):  \n",
    "  $$\n",
    "  J(w,b) = \\frac{1}{m} \\sum L(f^{(i)}, y^{(i)})\n",
    "  $$\n",
    "- Gradients:  \n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial w} = \\frac{1}{m} \\sum (f - y)x\n",
    "  $$\n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum (f - y)\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Implementation\n",
    "- Implemented:\n",
    "  - `sigmoid(z)`\n",
    "  - logistic model function\n",
    "  - loss function\n",
    "  - cost function\n",
    "  - gradient computation\n",
    "  - full gradient descent loop\n",
    "- Used the **Breast Cancer dataset**\n",
    "- Performed:\n",
    "  - Train/Test split\n",
    "  - Feature scaling\n",
    "  - Training via Gradient Descent\n",
    "  - Cost convergence monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Evaluation\n",
    "- Converted probabilities → class predictions (threshold 0.5)\n",
    "- Computed:\n",
    "  - Accuracy\n",
    "  - Confusion Matrix\n",
    "  - Precision, Recall, F1\n",
    "- Compared performance with:\n",
    "  - `sklearn.linear_model.LogisticRegression`\n",
    "\n",
    "Both GD and sklearn models achieved **high accuracy (~94%–97%)**, confirming correct implementation.\n",
    "\n",
    "---\n",
    "\n",
    "### ✔ Completed Day 2 Successfully!\n",
    "This concludes the Logistic Regression unit, setting the foundation for Neural Networks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
