### Day 5 â€” Gradient Boosting (Introduction to Boosting)

**Goal:**  
Understand boosting as an alternative ensemble learning strategy and compare it
with Random Forests.

**What was done:**
- Trained Random Forest as baseline model
- Trained Gradient Boosting model on the same dataset
- Compared training and test performance of both methods
- Studied effect of learning rate on boosting behavior
- Extracted and analyzed feature importance from Gradient Boosting

**Key Learning:**  
Boosting builds models sequentially to reduce bias, while Random Forest reduces
variance through averaging. With proper learning rate control, Gradient Boosting
can often achieve higher accuracy on structured datasets.