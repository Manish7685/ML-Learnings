{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98092076-62e5-417f-9f46-0800bfa24335",
   "metadata": {},
   "source": [
    "# Day 3 — Model Comparison Using Cross-Validation\n",
    "### Machine Learning Roadmap — Week 3\n",
    "### Author — N Manish Kumar\n",
    "---\n",
    "\n",
    "In previous notebooks, we evaluated individual models and tuned\n",
    "hyperparameters using cross-validation.\n",
    "\n",
    "However, in real ML problems, we often need to **compare different models**\n",
    "and choose the best one based on reliable evaluation metrics.\n",
    "\n",
    "Using test accuracy to compare multiple models leads to overfitting to the\n",
    "test set and unreliable conclusions.\n",
    "\n",
    "Instead, we compare models using **cross-validation on training data** and\n",
    "consider both:\n",
    "- Mean accuracy\n",
    "- Stability (standard deviation across folds)\n",
    "\n",
    "In this notebook, we will:\n",
    "- Compare multiple models using 5-fold cross-validation\n",
    "- Analyze mean and standard deviation of accuracy\n",
    "- Select the best model based on reliability, not just peak accuracy\n",
    "\n",
    "Dataset used: **Breast Cancer Dataset (sklearn)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Libraries, Load Dataset, and Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82af345b-dc5f-42f1-ab49-388625733837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (455, 30)\n",
      "Test set shape: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Train-test split (hold-out test set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f51054-50ff-4c94-a5b7-6195c79fe86b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Define Models for Comparison\n",
    "\n",
    "To compare models fairly, all preprocessing must be applied consistently.\n",
    "\n",
    "We will compare the following models:\n",
    "\n",
    "1. Logistic Regression (with regularization)\n",
    "2. Logistic Regression (stronger regularization)\n",
    "3. Decision Tree (simple non-linear model)\n",
    "\n",
    "For Logistic Regression, we use Pipelines to ensure that feature scaling\n",
    "is applied correctly inside each cross-validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80dac0cd-bc06-49f5-9ebb-1f809ba54492",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression (C=1)\": Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(C=1, solver=\"saga\", max_iter=10000))\n",
    "    ]),\n",
    "    \n",
    "    \"Logistic Regression (C=0.1)\": Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(C=0.1, solver=\"saga\", max_iter=10000))\n",
    "    ]),\n",
    "    \n",
    "    \"Decision Tree (max_depth=5)\": DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddac14-e7f6-402f-8a1b-db2419df0a6e",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Using multiple models allows us to compare both linear and non-linear\n",
    "approaches on the same dataset.\n",
    "\n",
    "Pipelines are used for Logistic Regression to ensure that scaling does not\n",
    "leak information across cross-validation folds.\n",
    "\n",
    "Decision Tree does not require feature scaling, so it is used directly.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Perform Cross-Validation for Each Model\n",
    "\n",
    "To compare models fairly, we evaluate each model using the same\n",
    "cross-validation strategy on the training data.\n",
    "\n",
    "For each model, we compute:\n",
    "- Mean cross-validation accuracy\n",
    "- Standard deviation of accuracy\n",
    "\n",
    "The standard deviation indicates how stable the model is across\n",
    "different data splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174ec120-32e6-4a53-b9f3-18a2ca0e450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression (C=1)': {'mean_accuracy': np.float64(0.9802197802197803),\n",
       "  'std_accuracy': np.float64(0.012815278889769896)},\n",
       " 'Logistic Regression (C=0.1)': {'mean_accuracy': np.float64(0.9802197802197803),\n",
       "  'std_accuracy': np.float64(0.016150481820548422)},\n",
       " 'Decision Tree (max_depth=5)': {'mean_accuracy': np.float64(0.9318681318681318),\n",
       "  'std_accuracy': np.float64(0.021308482889742106)}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results ={}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores= cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_results[name] ={\n",
    "        \"mean_accuracy\" : scores.mean(),\n",
    "        \"std_accuracy\": scores.std()\n",
    "    }\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8513e0b-3f7e-4d8c-a082-27ae426dad53",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Each model has now been evaluated using 5-fold cross-validation.\n",
    "\n",
    "Mean accuracy indicates overall performance, while standard deviation\n",
    "indicates how sensitive the model is to different data splits.\n",
    "\n",
    "In the next step, we will organize these results into a table to make\n",
    "model comparison easier and more interpretable.\n",
    "\n",
    "---\n",
    "## 5. Create Comparison Table\n",
    "\n",
    "To compare models clearly, we convert the cross-validation results into\n",
    "a structured table showing:\n",
    "\n",
    "- Model name\n",
    "- Mean cross-validation accuracy\n",
    "- Standard deviation of accuracy\n",
    "\n",
    "This makes it easier to select the best model based on both performance\n",
    "and stability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a698b4b8-ebf4-4fc3-9fb3-610769754e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (C=1)</th>\n",
       "      <td>0.980220</td>\n",
       "      <td>0.012815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (C=0.1)</th>\n",
       "      <td>0.980220</td>\n",
       "      <td>0.016150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (max_depth=5)</th>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.021308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean_accuracy  std_accuracy\n",
       "Logistic Regression (C=1)         0.980220      0.012815\n",
       "Logistic Regression (C=0.1)       0.980220      0.016150\n",
       "Decision Tree (max_depth=5)       0.931868      0.021308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(cv_results).T\n",
    "results_df = results_df.sort_values(by=\"mean_accuracy\", ascending=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e83b68-af9a-4b14-9283-d12e26f182e4",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The table shows which model achieves the highest average validation accuracy\n",
    "and how stable each model is across folds.\n",
    "\n",
    "A good model should have:\n",
    "- High mean accuracy\n",
    "- Low standard deviation\n",
    "\n",
    "Model selection should be based on these statistics, not on a single test\n",
    "set performance.\n",
    "\n",
    "---\n",
    "## 6. Final Test Set Evaluation of Best Model\n",
    "\n",
    "After selecting the best model using cross-validation on training data,\n",
    "we now evaluate that model on the untouched test set.\n",
    "\n",
    "This provides the final and most realistic estimate of how the selected\n",
    "model will perform on new, unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0cd3cf-d0d0-43e5-93ad-dd5e23105bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Logistic Regression (C=1)\n",
      "Final Test Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# Select best model based on CV results\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Train best model on full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Best Model:\", best_model_name)\n",
    "print(\"Final Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791d935-a877-4e9b-ae51-64a5378e3a1e",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "If the test accuracy is close to the cross-validation mean accuracy,\n",
    "it indicates that the model generalizes well and is not overfitting.\n",
    "\n",
    "This confirms that selecting the model using cross-validation provided\n",
    "a reliable choice for real-world performance.\n",
    "\n",
    "---\n",
    "# Notebook Summary — Week 3 Day 3\n",
    "\n",
    "In this notebook, we learned how to compare multiple machine learning models\n",
    "fairly using cross-validation instead of relying on a single test split.\n",
    "\n",
    "### What was done\n",
    "- Loaded and split the Breast Cancer dataset into training and test sets\n",
    "- Defined multiple models including Logistic Regression and Decision Tree\n",
    "- Evaluated each model using 5-fold cross-validation on training data\n",
    "- Computed mean and standard deviation of accuracy for each model\n",
    "- Created a comparison table to rank models based on performance and stability\n",
    "- Selected the best model using cross-validation results\n",
    "- Evaluated the selected model on the untouched test set\n",
    "\n",
    "### Key Learnings\n",
    "- Test set should not be used to compare multiple models\n",
    "- Cross-validation provides a reliable estimate of model performance\n",
    "- Mean accuracy reflects overall performance, while standard deviation reflects stability\n",
    "- Model selection should balance both accuracy and consistency across folds\n",
    "\n",
    "### Final Outcome\n",
    "Using cross-validation, the best-performing and most stable model was selected,\n",
    "and its test set performance confirmed good generalization to unseen data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
