{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52272d38-fac1-4ee2-a701-287f651d8708",
   "metadata": {},
   "source": [
    "# Day 4 — Error Analysis on Classification Models\n",
    "### Machine Learning Roadmap — Week 3\n",
    "### Author — N Manish Kumar\n",
    "---\n",
    "\n",
    "In previous days, we evaluated and compared models using cross-validation.\n",
    "However, overall accuracy does not tell us *where* the model is making mistakes.\n",
    "\n",
    "Error analysis focuses on inspecting **misclassified examples** to understand:\n",
    "- What types of cases the model fails on\n",
    "- Whether errors follow certain patterns\n",
    "- What kind of data or features could improve performance\n",
    "\n",
    "In this notebook, we will:\n",
    "- Train a classification model\n",
    "- Predict on the test set\n",
    "- Identify false positives and false negatives\n",
    "- Analyze feature patterns in misclassified samples\n",
    "- Discuss how the model could be improved\n",
    "\n",
    "Dataset used: **Breast Cancer Dataset (sklearn)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Libraries, Load Dataset and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608c0998-aecb-49ec-ae52-b2bf18df6f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (455, 30)\n",
      "Test set shape: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292d678-27de-4f9d-bff8-8dc909511108",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Train Model and Generate Predictions\n",
    "\n",
    "To analyze model errors, we first train a classification model on the\n",
    "training data and generate predictions on the test set.\n",
    "\n",
    "We use a Pipeline with StandardScaler and Logistic Regression to ensure\n",
    "proper preprocessing and stable training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74950925-e302-4720-a498-183c4436dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(solver=\"saga\", max_iter=10000))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9440ca-6e2e-442a-9cd7-af3f4e348d66",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The model is now trained using the training data and has generated\n",
    "predictions on the unseen test set.\n",
    "\n",
    "We can now compare predicted labels with true labels to identify\n",
    "which samples were classified correctly and which were misclassified.\n",
    "\n",
    "---\n",
    "## 3. Confusion Matrix and Error Types\n",
    "\n",
    "A confusion matrix shows how many predictions fall into each category:\n",
    "\n",
    "- True Positives (TP)\n",
    "- True Negatives (TN)\n",
    "- False Positives (FP)\n",
    "- False Negatives (FN)\n",
    "\n",
    "False Positives and False Negatives represent different types of mistakes\n",
    "and often have different real-world consequences.\n",
    "\n",
    "Analyzing these errors helps us understand which cases the model struggles with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd11bd5-a2ed-4777-800a-e9db5b796f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  1],\n",
       "       [ 1, 71]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c449aef-468a-4330-8696-1f2451df04bc",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The confusion matrix shows how many samples were correctly and incorrectly\n",
    "classified for each class.\n",
    "\n",
    "False Positives represent cases where the model predicted positive but the\n",
    "true label was negative.\n",
    "\n",
    "False Negatives represent cases where the model predicted negative but the\n",
    "true label was positive.\n",
    "\n",
    "In the next step, we will isolate these misclassified samples and inspect\n",
    "their feature values.\n",
    "\n",
    "---\n",
    "## 4. Inspect Misclassified Samples\n",
    "\n",
    "To understand model errors, we isolate the samples where predictions\n",
    "do not match the true labels.\n",
    "\n",
    "We separate:\n",
    "- False Positives (predicted positive, actually negative)\n",
    "- False Negatives (predicted negative, actually positive)\n",
    "\n",
    "By examining their feature values, we can look for patterns that may\n",
    "explain why the model struggled with these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d233678-9acc-4ee9-80d8-74d3122e5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of False Positives: 1\n",
      "Number of False Negatives: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 73         13.8         15.79           90.43      584.1           0.1007   \n",
       " \n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 73             0.128         0.07789              0.05069         0.1662   \n",
       " \n",
       "     mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       " 73                 0.06566  ...         16.57          20.86            110.3   \n",
       " \n",
       "     worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       " 73       812.4            0.1411             0.3542           0.2779   \n",
       " \n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       " 73                0.1383          0.2589                    0.103  \n",
       " \n",
       " [1 rows x 30 columns],\n",
       "      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 541        14.47         24.99           95.81      656.4          0.08837   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 541             0.123          0.1009               0.0389         0.1872   \n",
       " \n",
       "      mean fractal dimension  ...  worst radius  worst texture  \\\n",
       " 541                 0.06341  ...         16.22          31.73   \n",
       " \n",
       "      worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       " 541            113.5       808.9             0.134             0.4202   \n",
       " \n",
       "      worst concavity  worst concave points  worst symmetry  \\\n",
       " 541            0.404                0.1205          0.3187   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 541                   0.1023  \n",
       " \n",
       " [1 rows x 30 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify misclassified indices\n",
    "misclassified_idx = np.where(y_test != y_pred)[0]\n",
    "\n",
    "# True labels and predictions\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# False Positives: predicted 1, actual 0\n",
    "fp_idx = np.where((y_pred == 1) & (y_test_np == 0))[0]\n",
    "\n",
    "# False Negatives: predicted 0, actual 1\n",
    "fn_idx = np.where((y_pred == 0) & (y_test_np == 1))[0]\n",
    "\n",
    "print(\"Number of False Positives:\", len(fp_idx))\n",
    "print(\"Number of False Negatives:\", len(fn_idx))\n",
    "\n",
    "# View a few samples\n",
    "X_test_fp = X_test.iloc[fp_idx]\n",
    "X_test_fn = X_test.iloc[fn_idx]\n",
    "\n",
    "X_test_fp.head(), X_test_fn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17909948-8b72-4bb2-9b71-1e423da6e57c",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "False Positive samples are cases where the model predicted cancer but\n",
    "the true label was non-cancer, which could lead to unnecessary concern.\n",
    "\n",
    "False Negative samples are cases where the model missed actual cancer,\n",
    "which is usually more dangerous in medical applications.\n",
    "\n",
    "Inspecting feature values of these samples can reveal whether they\n",
    "look similar to the opposite class, making them difficult to classify.\n",
    "\n",
    "---\n",
    "## 5. Compare Feature Distributions for Errors vs Correct Predictions\n",
    "\n",
    "To understand why the model is confused, we compare feature values of:\n",
    "\n",
    "- Correctly classified samples\n",
    "- Misclassified samples (FP and FN)\n",
    "\n",
    "If misclassified samples have feature distributions similar to the opposite\n",
    "class, it indicates overlapping regions where linear models may struggle.\n",
    "\n",
    "We will compare simple summary statistics for selected important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e422d164-50ee-4f18-92c8-bf8a8dd706a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Mean</th>\n",
       "      <th>False Positive Mean</th>\n",
       "      <th>False Negative Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>14.371223</td>\n",
       "      <td>13.80000</td>\n",
       "      <td>14.47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>19.441786</td>\n",
       "      <td>15.79000</td>\n",
       "      <td>24.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>0.097176</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.08837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.10090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Correct Mean  False Positive Mean  False Negative Mean\n",
       "mean radius         14.371223             13.80000             14.47000\n",
       "mean texture        19.441786             15.79000             24.99000\n",
       "mean smoothness      0.097176              0.10070              0.08837\n",
       "mean concavity       0.087188              0.07789              0.10090"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indices of correctly classified samples\n",
    "correct_idx = np.where(y_test_np == y_pred)[0]\n",
    "\n",
    "X_test_correct = X_test.iloc[correct_idx]\n",
    "\n",
    "# Compare mean feature values for a few important features\n",
    "features_to_check = [\n",
    "    \"mean radius\",\n",
    "    \"mean texture\",\n",
    "    \"mean smoothness\",\n",
    "    \"mean concavity\"\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Correct Mean\": X_test_correct[features_to_check].mean(),\n",
    "    \"False Positive Mean\": X_test_fp[features_to_check].mean(),\n",
    "    \"False Negative Mean\": X_test_fn[features_to_check].mean()\n",
    "})\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d54915-624e-4f4a-89b2-981ba3f4d932",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "If False Positive or False Negative samples have feature averages closer to\n",
    "the opposite class than to correctly classified samples, it suggests that\n",
    "those cases lie near the decision boundary.\n",
    "\n",
    "This indicates that:\n",
    "- The classes overlap in feature space\n",
    "- A linear model may struggle to separate them perfectly\n",
    "\n",
    "In such cases, using more expressive models or engineering better features\n",
    "could help improve performance.\n",
    "\n",
    "---\n",
    "## 6. What Could Improve This Model?\n",
    "\n",
    "After identifying where the model makes mistakes, the next step is to\n",
    "decide how to improve performance logically instead of randomly tuning models.\n",
    "\n",
    "Based on error patterns, possible improvement strategies include:\n",
    "- Adding more informative features\n",
    "- Using non-linear models\n",
    "- Adjusting classification threshold\n",
    "- Collecting more training data in difficult regions\n",
    "\n",
    "Error analysis helps prioritize which action is most likely to help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd60634-7238-4802-aa58-86e861bab42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive probabilities (first 5): [0.90864595]\n",
      "False Negative probabilities (first 5): [0.3642837]\n"
     ]
    }
   ],
   "source": [
    "# Get prediction probabilities\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Probabilities of misclassified samples\n",
    "fp_probs = y_prob[fp_idx]\n",
    "fn_probs = y_prob[fn_idx]\n",
    "\n",
    "print(\"False Positive probabilities (first 5):\", fp_probs[:5])\n",
    "print(\"False Negative probabilities (first 5):\", fn_probs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ba0d8-3fdc-4ba7-b068-53b85c3f0ef5",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "If misclassified samples have probabilities close to 0.5, it indicates\n",
    "that the model was uncertain and the samples lie near the decision boundary.\n",
    "\n",
    "This suggests that:\n",
    "- Small changes in features could flip predictions\n",
    "- A more expressive model (e.g., tree-based) may separate classes better\n",
    "\n",
    "Error analysis therefore guides whether to:\n",
    "- Improve features\n",
    "- Change model family\n",
    "- Tune thresholds depending on application needs\n",
    "\n",
    "---\n",
    "# Notebook Summary — Week 3 Day 4\n",
    "\n",
    "In this notebook, we performed error analysis to understand where and why\n",
    "a classification model makes mistakes instead of relying only on accuracy.\n",
    "\n",
    "### What was done\n",
    "- Trained a Logistic Regression model using a proper pipeline\n",
    "- Generated predictions on the untouched test set\n",
    "- Built a confusion matrix to identify error types\n",
    "- Isolated false positives and false negatives\n",
    "- Compared feature patterns of correct and incorrect predictions\n",
    "- Analyzed prediction probabilities for misclassified samples\n",
    "\n",
    "### Key Learnings\n",
    "- Overall accuracy does not reveal specific failure cases\n",
    "- Error analysis helps identify overlapping class regions\n",
    "- False negatives and false positives have different real-world impacts\n",
    "- Misclassified samples often lie near the decision boundary\n",
    "- Improvement strategies should be guided by error patterns\n",
    "\n",
    "### Final Outcome\n",
    "The analysis showed that many errors occur in regions where class features\n",
    "overlap, suggesting that better features or more expressive models could\n",
    "improve performance more effectively than blind tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
